{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!export PYTHONPATH=$PYTHONPATH:/data1/practical-sose23/castellvi/castellvi_prediction/bids\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/data1/practical-sose23/castellvi/castellvi_prediction/bids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1354954/466627274.py\", line 1, in <module>\n",
      "    from dataset.VerSe import VerSe\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 992, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/u/home/ank/3D-Castellvi-Prediction/src/dataset/__init__.py\", line 3, in <module>\n",
      "    from utils._prepare_data import DataHandler\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 992, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/u/home/ank/3D-Castellvi-Prediction/src/utils/__init__.py\", line 2, in <module>\n",
      "    from ._prepare_data import DataHandler\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/u/home/ank/3D-Castellvi-Prediction/src/utils/_prepare_data.py\", line 8, in <module>\n",
      "    from pqdm.processes import pqdm\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/pqdm/processes.py\", line 6, in <module>\n",
      "    from tqdm.auto import tqdm as tqdm_auto\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py\", line 21, in <module>\n",
      "    from .autonotebook import tqdm as notebook_tqdm\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/u/home/ank/.conda/envs/myenv/lib/python3.10/site-packages/tqdm/autonotebook.py\", line 19, in <module>\n",
      "    warn(WARN_NOIPYW, TqdmWarning, stacklevel=2)\n",
      "####################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-14 22:27:55,490 - Created a temporary directory at /tmp/tmpeu8t6xxu\n",
      "2023-07-14 22:27:55,492 - Writing /tmp/tmpeu8t6xxu/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "from dataset.VerSe import VerSe\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, cohen_kappa_score, confusion_matrix\n",
    "from modules.DenseNetModule import DenseNet\n",
    "from utils._prepare_data import DataHandler\n",
    "from utils.environment_settings import env_settings\n",
    "\n",
    "import BIDS\n",
    "from BIDS import BIDS_Global_info, BIDS_Family, NII\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "import monai\n",
    "#from monai.networks.utils import eval_mode\n",
    "from monai.transforms import (\n",
    "    AddChannel, Compose, LoadImage, RandRotate90, NormalizeIntensity, RandScaleIntensity,\n",
    "    Resize, ScaleIntensityRange, ToTensor, ScaleIntensity, RandShiftIntensity,CropForeground,\n",
    "    RandFlip, RandSpatialCrop, ResizeWithPadOrCrop, Spacing, ThresholdIntensity, Orientation\n",
    ")\n",
    "from monai.metrics import compute_roc_auc\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet loaded with 3 classes, data_size (96, 78, 78) and 1 channel\n",
      "[!] Unknown format seg-ano in file sub-verse649_dir-sag_seg-ano.nii.gz\n",
      "[!] Unknown format iso-ctd in file sub-verse616_dir-iso_iso-ctd.json\n",
      "[!] \"template\" is not a valid key/value pair. Expected \"KEY-VALUE\" in sub-verse519_template_sacrum_msk.nii.gz\n",
      "[!] \"sacrum\" is not a valid key/value pair. Expected \"KEY-VALUE\" in sub-verse519_template_sacrum_msk.nii.gz\n",
      "[!] Unknown format subreg in file verse559_CT-sag_seg-ano_subreg.nii.gz\n",
      "[!] \"verse559\" is not a valid key/value pair. Expected \"KEY-VALUE\" in verse559_CT-sag_seg-ano_subreg.nii.gz\n",
      "[!] \"verse559\" is not a valid key/value pair. Expected \"KEY-VALUE\" in verse559_CT-sag_seg-ano.nii.gz\n",
      "[!] \"verse549\" is not a valid key/value pair. Expected \"KEY-VALUE\" in verse549_CT-iso_seg-ano.nii.gz\n",
      "[!] Unknown format ce-ar in file sub-tri106_ce-ar.nii.gz\n",
      "[!] Unknown format ce-pv in file sub-tri066_ce-pv.nii.gz\n",
      "[!] Unknown format ce-ne in file sub-tri067_ce-ne.nii.gz\n",
      "[!] Unknown format ce-late in file sub-tri023_ce-late.nii.gz\n",
      "[!] Unknown format stat in file sub-tri106_ce-pv_seg-total_stat.json\n"
     ]
    }
   ],
   "source": [
    "dataset = [os.path.join(env_settings.DATA, \"dataset-verse19\"), os.path.join(env_settings.DATA, \"dataset-verse20\"), os.path.join(env_settings.DATA, \"dataset-tri\")]\n",
    "data_types = ['rawdata',\"derivatives\"]\n",
    "image_types = [\"ct\", \"subreg\", \"cortex\"]\n",
    "\n",
    "ckpt_path = \"/data1/practical-sose23/castellvi/team_repo/3D-Castellvi-Prediction/experiments/baseline_models/densenet/best_models/version_0/densenet-epoch=38-val_mcc=0.91.ckpt\"\n",
    "master_list_new = '/data1/practical-sose23/castellvi/team_repo/3D-Castellvi-Prediction/src/dataset/Castellvi_list_Final_Split_v2.xlsx'\n",
    "#Load model, processor and dataset\n",
    "model = DenseNet.load_from_checkpoint(ckpt_path)\n",
    "processor = DataHandler(master_list = master_list_new, dataset=dataset, data_types=data_types, image_types=image_types)\n",
    "verse_dataset = VerSe(model.opt, processor, processor.verse_records + processor.tri_records, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each record with dataset_split = val, get index of both flipped and non-flipped records\n",
    "val_subjects = [record[\"subject\"] for record in verse_dataset.records if (record[\"dataset_split\"] == \"val\" and record[\"flip\"] == 1)]\n",
    "len(val_subjects)\n",
    "\n",
    "val_subs_joined = {}\n",
    "val_subs_idx = []\n",
    "for subject in val_subjects:\n",
    "    val_subs_joined[subject] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each record with dataset_split = val, get index of both flipped and non-flipped records\n",
    "val_records = [record for record in verse_dataset.records if (record[\"dataset_split\"] == \"val\" and record[\"flip\"] == 1)]\n",
    "len(val_subjects)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Eval(model.opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'seg_comparison'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_record \u001b[39m=\u001b[39m val_records[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m model_inputs \u001b[39m=\u001b[39m evaluator\u001b[39m.\u001b[39;49mprocess_input(processor, sample_record)\n\u001b[1;32m      3\u001b[0m input_img \u001b[39m=\u001b[39m model_inputs[\u001b[39m'\u001b[39m\u001b[39moriginal\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# you can also get flipped one by model_inputs['flipped']\u001b[39;00m\n\u001b[1;32m      4\u001b[0m output_class, output_prob \u001b[39m=\u001b[39m evaluator\u001b[39m.\u001b[39mprocess_output(model, input_img)\n",
      "File \u001b[0;32m~/3D-Castellvi-Prediction/src/eval.py:304\u001b[0m, in \u001b[0;36mEval.process_input\u001b[0;34m(self, processor, record)\u001b[0m\n\u001b[1;32m    301\u001b[0m     lsac_mask \u001b[39m=\u001b[39m ndimage\u001b[39m.\u001b[39mbinary_dilation(lsac_mask, iterations\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    302\u001b[0m     img \u001b[39m=\u001b[39m img \u001b[39m*\u001b[39m lsac_mask\n\u001b[0;32m--> 304\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_model_inputs(img)\n\u001b[1;32m    305\u001b[0m \u001b[39mreturn\u001b[39;00m model_inputs\n",
      "File \u001b[0;32m~/3D-Castellvi-Prediction/src/eval.py:253\u001b[0m, in \u001b[0;36mEval.get_model_inputs\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    249\u001b[0m model_inputs[\u001b[39m\"\u001b[39m\u001b[39moriginal\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m original_img_tensor\n\u001b[1;32m    250\u001b[0m model_inputs[\u001b[39m\"\u001b[39m\u001b[39mflipped\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m flipped_img_tensor\n\u001b[0;32m--> 253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopt\u001b[39m.\u001b[39;49mseg_comparison:\n\u001b[1;32m    254\u001b[0m     \u001b[39m# Get dilated images\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     dilated_img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_dilated_input(sacrum_seg, last_l_seg, s_idx, l_idx)\n\u001b[1;32m    256\u001b[0m     flipped_dilated_img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_dilated_input(flipped_sacrum_seg, flipped_last_l_seg, flipped_s_idx, flipped_l_idx)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'seg_comparison'"
     ]
    }
   ],
   "source": [
    "sample_record = val_records[0]\n",
    "model_inputs = evaluator.process_input(processor, sample_record)\n",
    "input_img = model_inputs['original'] # you can also get flipped one by model_inputs['flipped']\n",
    "output_class, output_prob = evaluator.process_output(model, input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campp = monai.visualize.GradCAMpp(nn_module = model, target_layers = \"network.features.denseblock4.denselayer32.layers.conv2\", )\n",
    "win_size = (96, 78, 78)\n",
    "print(\"original feature shape\", campp.feature_map_size([1, 1] + list(win_size), device) )\n",
    "print(\"upsampled feature shape\", [1, 1] + list(win_size), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_names(model):\n",
    "    layer_names = []\n",
    "    for name, _ in model.named_parameters():\n",
    "        # Split the name by '.' and keep the first part\n",
    "        layer_name = name\n",
    "        if layer_name not in layer_names:\n",
    "            layer_names.append(layer_name)\n",
    "    return layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = get_layer_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers_list = []\n",
    "for i in range(len(layer_names)):\n",
    "    layer = layer_names[i]\n",
    "    if 'conv' not in layer:\n",
    "        continue\n",
    "    else:\n",
    "        conv_layers_list.append(layer)\n",
    "    print(i , layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campp_result = campp( x= input_img , class_idx=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay Original image and GradCAM heatmap\n",
    "def superimposed_image_def(camp_results, original_img, alpha = 0.6):\n",
    "    all_images_slices = []\n",
    "    all_heatmap_results = []\n",
    "    print(input_img.shape[2]-1)\n",
    "    for i in range(input_img.shape[-1]):\n",
    "        print(i)\n",
    "        original_image_slice= original_img.detach().cpu().numpy()[..., i]\n",
    "        original_image_slice = original_image_slice[0,0,:,:] \n",
    "        print('original_img shape:', original_image_slice.shape)\n",
    "        print('original_img data type:', original_image_slice.dtype)\n",
    "        # Make 1-channel image to 3-channel : To overlay this image with the heatmap (JET colormap = 3-channels)\n",
    "        original_image_slice = cv2.merge((original_image_slice, original_image_slice, original_image_slice))\n",
    "        camp_result_slice = camp_results.detach().cpu().numpy()[..., i]\n",
    "        camp_result_slice = camp_result_slice[0,0,:,:] # Same above\n",
    "        print('cam_img shape:', camp_result_slice.shape)\n",
    "        print('cam_img data type:', camp_result_slice.dtype)\n",
    "        camp_result_slice = np.maximum(camp_result_slice, 0)\n",
    "\n",
    "\n",
    "        # Convert Class Activation Map to 0 - 255\n",
    "        camp_result_slice = (camp_result_slice - camp_result_slice.min()) / (\n",
    "                camp_result_slice.max() - camp_result_slice.min()\n",
    "        )\n",
    "        camp_result_slice = np.uint8(255 * camp_result_slice)\n",
    "\n",
    "        # Convert to Heatmap ---- JET COLORMAP\n",
    "        camp_result_slice = cv2.applyColorMap(camp_result_slice, cv2.COLORMAP_JET)\n",
    "\n",
    "        # Superimpose Heatmap on Image Data\n",
    "        original_image_slice = np.uint8(\n",
    "            (original_image_slice - original_image_slice.min())\n",
    "            / (original_image_slice.max() - original_image_slice.min())\n",
    "            * 255\n",
    "        )\n",
    "\n",
    "        superimposed_image =np.uint8(np.uint8(original_image_slice) * alpha + camp_result_slice * (1 - alpha))\n",
    "        all_images_slices.append(superimposed_image)\n",
    "        all_heatmap_results.append(camp_result_slice)\n",
    "        \n",
    "\n",
    "    return all_images_slices, all_heatmap_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imposed_img , heatmap = superimposed_image_def(campp_result, input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(heatmap[30])\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(imposed_img[30])\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation, rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('animation', html='jshtml')\n",
    "\n",
    "\n",
    "def create_animation(array):\n",
    "    \"\"\"Create an animation of a volume\"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    images = []\n",
    "    for idx, image in enumerate(array):\n",
    "        # plot image without notifying animation\n",
    "        image_plot = plt.imshow(image, animated=True, cmap='bone')\n",
    "        aux = [image_plot]\n",
    "        images.append(aux)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "    plt.title(f'Deneme', fontsize=16)\n",
    "    \n",
    "    ani = animation.ArtistAnimation(\n",
    "        fig, images, interval=5000//len(array), blit=False, repeat_delay=1000)\n",
    "    plt.close()\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_animation(imposed_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
